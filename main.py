import os
from dotenv import load_dotenv
load_dotenv()
import streamlit as st
import torch
from transformers import BertModel, BertTokenizerFast
from huggingface_hub import hf_hub_download
from model import PunctuationCapitalizationRNN, PUNCT_TAGS, CAP_TAGS
from utils import predict_and_reconstruct, save_feedback
from google import genai
from google.genai import types

client = genai.Client(
    api_key= st.secrets["GOOGLE_GENAI_API_KEY"] or os.getenv("GOOGLE_GENAI_API_KEY"),
)

@st.cache_resource
def load_model():
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    # 1) Reconstru√≠s BERT y aplic√°s freeze/fine-tuning parcial
    bert = BertModel.from_pretrained("bert-base-multilingual-cased")
    for p in bert.embeddings.word_embeddings.parameters(): p.requires_grad = False
    for layer in bert.encoder.layer[-2:]:
        for p in layer.parameters(): p.requires_grad = True
    for p in bert.pooler.parameters(): p.requires_grad = True

    # 2) Instanci√°s tu RNN
    model = PunctuationCapitalizationRNN(
        bert_model=bert,
        hidden_dim=256,
        num_punct_classes=len(PUNCT_TAGS),
        num_cap_classes=len(CAP_TAGS),
        dropout=0.3
    ).to(device)

    # 3) Descarg√°s el state_dict desde HF Hub
    #    repo_id = "fabroo/PunctuationCapitalizationRNN"
    state_path = hf_hub_download(
        repo_id="fabroo/PunctuationCapitalizationRNN",
        filename="modelo_fine_tuned_state_dict.pt"
    )
    state_dict = torch.load(state_path, map_location=device)
    model.load_state_dict(state_dict)

    # 4) Modo evaluaci√≥n
    model.eval()
    return model

@st.cache_resource
def load_tokenizer():
    return BertTokenizerFast.from_pretrained("bert-base-multilingual-cased")

model     = load_model()
tokenizer = load_tokenizer()

st.title("Reconstrucci√≥n de Texto con Puntuaci√≥n y Capitalizaci√≥n")

st.info("""
‚úçÔ∏è *Instrucciones:*  
Ingres√° una frase sin puntuaci√≥n ni may√∫sculas, por ejemplo:  
`hola que lindo dia que hace no te parece`

El modelo la corregir√° autom√°ticamente:  
`Hola, qu√© lindo d√≠a que hace, ¬øno te parece?`
""")

st.markdown("""
    <style>
    input[type="text"] {
        text-transform: lowercase;
    }
    </style>
""", unsafe_allow_html=True)

sentence = st.text_input("Ingres√° texto:")
sentence = sentence.lower()

if sentence:
    result = predict_and_reconstruct(model, sentence.lower(), tokenizer)
    st.write("**Resultado Modelo:**", result)
    
    response = client.models.generate_content(
        model="gemini-2.5-flash",
        contents="Por favor, revisa el siguiente texto y realiza las correcciones necesarias en puntuaci√≥n y capitalizaci√≥n:\n\n" + result 
        + "\n\nAseg√∫rate de que el texto est√© correctamente puntuado y capitalizado."
        + "\n\n**Nota:** No agregues ni elimines palabras, solo corrige la puntuaci√≥n y la capitalizaci√≥n."
        + "\n\n SOLO DEVOLV√â EL TEXTO CORREGIDO, SIN EXPLICACIONES NI COMENTARIOS.",
        config=types.GenerateContentConfig(
            thinking_config=types.ThinkingConfig(thinking_budget=0)
        ),
    )
    if response and response.text:
        st.write("**Resultado Gemini 2.5 Flash:**", response.text)


    st.markdown("üí° ¬øEl resultado no fue correcto? Pod√©s enviarnos tu feedback con el bot√≥n de abajo:")

    if st.button("üì¨ Enviar feedback: el modelo se equivoc√≥"):
        save_feedback(sentence, result)
        st.success("‚úÖ ¬°Gracias! Tu feedback fue guardado.")
