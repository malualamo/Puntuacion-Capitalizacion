{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fabro/Documents/uba/aprendizaje_automatico/Puntualizacion-Capitalizacion/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from collections import Counter\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from utils.datautils import *\n",
    "from utils.MLutils import *\n",
    "from utils.resources import *\n",
    "from transformers import BertTokenizerFast\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertModel\n",
    "import unicodedata\n",
    "\n",
    "# linea que arregla algunos errores de loadeo de datasets\n",
    "#pip install --upgrade datasets\n",
    "\n",
    "# linea que corre torch acelerado en mac\n",
    "# pip3 install --pre torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/nightly/cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Procesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usando: cuda\n"
     ]
    }
   ],
   "source": [
    "linux = True\n",
    "device = None\n",
    "\n",
    "if linux:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "else:\n",
    "    device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "print(\"usando:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-multilingual-cased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejericio b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Busqueda de fuentes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fuente 1: Conjunto de preguntas en espa;ol\n",
    "- Fuente 2: Dataset provisto para Notebook 10\n",
    "- Fuente 3: Dataset sintetico generado con Gemini\n",
    "- Fuente 4: Articulos de Wikipedia\n",
    "- Fuente 5: Subtitulos de peliculas\n",
    "- Fuente 6: Mixture of preguntas y afirmaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se descargaron 5000 preguntas en Español.\n",
      "Se descargaron 997 oraciones en Español (del dataset del notebook 10).\n",
      "Hay 1413 oraciones sintéticas.\n",
      "['Argentina, oficialmente República Argentina,[a]\\u200b es un país soberano de América del Sur, ubicado en el extremo sur y sudeste de ese subcontinente.', 'Adopta la forma de gobierno republicana, democrática, representativa y federal.', 'Poseen Carta Magna, bandera y fuerzas de seguridad propias, el dominio de los recursos naturales circunscriptos en su territorio y delegan los poderes exclusivos al Gobierno Federal.', 'Hasta mediados del siglo XX, fue una de las economías más prósperas del mundo.', 'No obstante, es la segunda economía más importante de Sudamérica —detrás de Brasil— y la 24.º más grande del mundo por PIB nominal.']\n",
      "✅ Se extrajeron 947 frases completas y se guardaron en 'dialogos_esperando_la_carroza.json'\n",
      "✅ Frases extraídas y guardadas. Total: 947\n",
      "['La canilla está cerrada.', '¿Qué te dijo?', 'Ah... Ahora se acuerdan de su buen nombre, ¿viste?...', 'Veinte años, qué jovencita. ¿Y cuándo nació?, porque el padre murió antes del embarazo, entonces.', 'Estuve, estuve ahí, ahí enfrente, en lo de la Dominga, ¿te acordás? Elisa.- Pero, ¿todo el día?', 'Elvira: el teléfono.', 'Yo no me lo voy a perdonar nunca.', 'Está bien. Declme: ¿vos estás amamantando, Dominga?', '¿Qué?', 'Eh, es muy corto...']\n",
      "✅ Se extrajeron 1000 frases de Relatos Salvajes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Mi amigo de Nicaragua, llamado Javier, es un poeta muy reconocido. ¿Qué ha solicitado Cándido Méndez?',\n",
       " '¿Quiénes eran los personajes que podían verse habitualmente en las obras shunga? Quiero una doble Whopper de Burger King.',\n",
       " '¿Cuál creen los historiadores actuales que es el motivo del carácter de Calígula? ¿Quién es Ana Botella?',\n",
       " 'El logo de Adidas Originals es un trébol. ¿Qué organización humanitaria tuvo origen en Suiza?',\n",
       " '¿Cómo es el campus de la Ciudadela Robledo? ¿Dónde se presentó El alquimista impaciente?']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions, question_for_mixture = get_questions()\n",
    "oraciones_rnn = get_notebook_dataset()\n",
    "oraciones_sinteticas = get_gemini_dataset()\n",
    "frases_wikipedia = get_wikipedia_dataset()\n",
    "esperando_la_carroza, frases_relatos_salvajes = get_pelis_dataset()\n",
    "\n",
    "cant_oraciones = len(oraciones_sinteticas)\n",
    "question_for_mixture = [re.sub(r'[\\\\\\(\\)!¡“]', '', unicodedata.normalize(\"NFC\", q).strip()) for q in question_for_mixture]\n",
    "oraciones_sinteticas = [re.sub(r'[\\\\\\(\\)!¡“]', '', unicodedata.normalize(\"NFC\", a).strip()) for a in oraciones_sinteticas]\n",
    "\n",
    "tanda_1 = question_for_mixture[:cant_oraciones]\n",
    "question_affirmation = [f\"{q} {a}\" for q, a in zip(tanda_1, oraciones_sinteticas)]\n",
    "\n",
    "tanda_2 = question_for_mixture[cant_oraciones:2*cant_oraciones]\n",
    "affirmation_question = [f\"{a} {q}\" for q, a in zip(tanda_2, oraciones_sinteticas)]\n",
    "\n",
    "tanda_3 = question_for_mixture[2*cant_oraciones:3*cant_oraciones]\n",
    "tanda_3_shuffled = random.sample(tanda_3, len(tanda_3))\n",
    "question_question = [f\"{q} {p}\" for q, p in zip(tanda_3, tanda_3_shuffled)]\n",
    "\n",
    "mixtures = question_affirmation + affirmation_question + question_question\n",
    "\n",
    "random.sample(mixtures, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Juntamos las fuentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad total de oraciones: 20244\n",
      "Cantidad de oraciones de preguntas: 5000\n",
      "Cantidad de oraciones en espa;ol de hugging face: 997\n",
      "Cantidad de oraciones sintéticas: 1413\n",
      "Cantidad de oraciones de Wikipedia: 6648\n",
      "Cantidad de oraciones de Esperando la carroza: 947\n",
      "Cantidad de oraciones de Relatos Salvajes: 1000\n",
      "Cantidad de oraciones de mixture: 4239\n",
      "Algunas oraciones aleatorias:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['El nuevo año comenzó con problemas, debido a que la comisión directiva del club había decidido contratar a Carlos Bilardo como director técnico.',\n",
       " '¿Que hace? Pera',\n",
       " 'F., mientras que Messi hacía lo propio con el F.',\n",
       " 'Ai, la concha de la novia.',\n",
       " 'Pero aún así, el día de la mujer debe celebrarse como lo son otras fiestas\".[45]\\u200b\\nEn 1975, la ONU celebró el Año Internacional de la Mujer.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oraciones_raw = questions + oraciones_rnn + oraciones_sinteticas + frases_wikipedia + esperando_la_carroza  + frases_relatos_salvajes + mixtures\n",
    "\n",
    "print('Cantidad total de oraciones:',len(oraciones_raw))\n",
    "print('Cantidad de oraciones de preguntas:',len(questions))\n",
    "print('Cantidad de oraciones en espa;ol de hugging face:',len(oraciones_rnn))\n",
    "print('Cantidad de oraciones sintéticas:',len(oraciones_sinteticas))\n",
    "print('Cantidad de oraciones de Wikipedia:',len(frases_wikipedia))\n",
    "print('Cantidad de oraciones de Esperando la carroza:',len(esperando_la_carroza))\n",
    "print('Cantidad de oraciones de Relatos Salvajes:',len(frases_relatos_salvajes))\n",
    "print('Cantidad de oraciones de mixture:',len(mixtures))\n",
    "\n",
    "print(\"Algunas oraciones aleatorias:\")\n",
    "random.sample(oraciones_raw, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separamos en conjuntos de `train` y `test` con el tokenizer de `BERT`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19231\n",
      "1013\n"
     ]
    }
   ],
   "source": [
    "train_sents, test_sents = train_test_split(oraciones_raw, test_size=0.05, random_state=42)\n",
    "\n",
    "dataloader_train = get_dataloader(oraciones_raw=oraciones_raw, max_length=64, batch_size=64, device=device, tokenizer=tokenizer)\n",
    "dataloader_test = get_dataloader(oraciones_raw=test_sents, max_length=64, batch_size=64, device=device, tokenizer=tokenizer)\n",
    "\n",
    "print(len(train_sents))\n",
    "print(len(test_sents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train.RNN import PunctuationCapitalizationRNN\n",
    "\n",
    "model_name = \"bert-base-multilingual-cased\"\n",
    "bert_model = BertModel.from_pretrained(model_name)\n",
    "\n",
    "for param in bert_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in bert_model.embeddings.word_embeddings.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "N = 2\n",
    "for layer in bert_model.encoder.layer[-N:]:\n",
    "    for param in layer.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "# ver que es pooler\n",
    "for param in bert_model.pooler.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PunctuationCapitalizationRNN(\n",
    "    bert_model = bert_model,\n",
    "    hidden_dim=256,\n",
    "    num_punct_start_classes=len(PUNCT_START_TAGS),\n",
    "    num_punct_end_classes=len(PUNCT_END_TAGS),\n",
    "    num_cap_classes=len(CAP_TAGS)\n",
    ").to(device)\n",
    "\n",
    "\n",
    "punct_start_counter = Counter()\n",
    "punct_end_counter = Counter()\n",
    "cap_counter = Counter()\n",
    "for input_ids, attention_mask, punct_start_labels, punct_end_labels, cap_labels in dataloader_train:\n",
    "    punct_start_np = punct_start_labels.cpu().numpy()\n",
    "    punct_end_np   = punct_end_labels.cpu().numpy()\n",
    "    cap_np         = cap_labels.cpu().numpy()\n",
    "\n",
    "    valid_start = punct_start_np[punct_start_np != -100]\n",
    "    valid_end   = punct_end_np[punct_end_np != -100]\n",
    "    valid_cap   = cap_np[cap_np != -100]\n",
    "\n",
    "    punct_start_counter.update(valid_start)\n",
    "    punct_end_counter.update(valid_end)\n",
    "    cap_counter.update(valid_cap)\n",
    "\n",
    "total_start = sum(punct_start_counter.values())\n",
    "total_end   = sum(punct_end_counter.values())\n",
    "total_cap   = sum(cap_counter.values())\n",
    "beta = 0.7\n",
    "\n",
    "start_weights = {\n",
    "    tag: (total_start / count)**beta\n",
    "    for tag, count in punct_start_counter.items()\n",
    "}\n",
    "end_weights = {\n",
    "    tag: (total_end / count)**beta\n",
    "    for tag, count in punct_end_counter.items()\n",
    "}\n",
    "cap_weights = {\n",
    "    tag: (total_cap / count)**beta\n",
    "    for tag, count in cap_counter.items()\n",
    "}\n",
    "\n",
    "start_weights_tensor = torch.tensor(\n",
    "    [start_weights.get(i, 1.0) for i in range(len(PUNCT_START_TAGS))],\n",
    "    dtype=torch.float32\n",
    ").to(device).clamp(min=1.0, max=5.0)\n",
    "\n",
    "end_weights_tensor = torch.tensor(\n",
    "    [end_weights.get(i, 1.0) for i in range(len(PUNCT_END_TAGS))],\n",
    "    dtype=torch.float32\n",
    ").to(device).clamp(min=1.0, max=5.0)\n",
    "\n",
    "cap_weights_tensor = torch.tensor(\n",
    "    [cap_weights.get(i, 1.0) for i in range(len(CAP_TAGS))],\n",
    "    dtype=torch.float32\n",
    ").to(device).clamp(min=1.0, max=5.0)\n",
    "\n",
    "\n",
    "criterion_start = nn.CrossEntropyLoss(ignore_index=-100, weight=start_weights_tensor)\n",
    "criterion_end   = nn.CrossEntropyLoss(ignore_index=-100, weight=end_weights_tensor)\n",
    "criterion_cap   = nn.CrossEntropyLoss(ignore_index=-100, weight=cap_weights_tensor)\n",
    "\n",
    "trainable_params = [\n",
    "    p for p in bert_model.parameters() if p.requires_grad\n",
    "] + list(model.projection.parameters()) \\\n",
    "  + list(model.rnn.parameters()) \\\n",
    "  + list(model.punct_start_classifier.parameters()) \\\n",
    "  + list(model.punct_end_classifier.parameters()) \\\n",
    "  + list(model.cap_classifier.parameters())\n",
    "\n",
    "optimizer = torch.optim.AdamW(trainable_params, lr=2e-5)\n",
    "\n",
    "train(model, dataloader_train=dataloader_train, dataloader_test=dataloader_test,optimizer=optimizer, criterion_start=criterion_start,criterion_end=criterion_end, criterion_cap = criterion_cap, device=device, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo cargado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = PunctuationCapitalizationRNN(\n",
    "    bert_model = bert_model,\n",
    "    hidden_dim=256,\n",
    "    num_punct_start_classes=len(PUNCT_START_TAGS),\n",
    "    num_punct_end_classes=len(PUNCT_END_TAGS),\n",
    "    num_cap_classes=len(CAP_TAGS)\n",
    ").to(device)\n",
    "\n",
    "model.load_state_dict(torch.load(\"model_rnn_tres_cabezas.pt\", map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrada: no te lo puedo creer messi se va a retirar\n",
      "Salida: No, te lo puedo, creer, Messi, se va a retirar.\n"
     ]
    }
   ],
   "source": [
    "entrada = \"no te lo puedo creer messi se va a retirar\"\n",
    "\n",
    "print(f\"Entrada: {entrada}\")\n",
    "print(f\"Salida: {predict_and_reconstruct(model, entrada, tokenizer, device, verbose=False)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Acc: 0.9980\n",
      "End   Acc: 0.9709\n",
      "Cap   Acc: 0.9840\n",
      "\n",
      "Start report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           Ø       1.00      1.00      1.00     21732\n",
      "           ¿       0.95      0.98      0.96       579\n",
      "\n",
      "    accuracy                           1.00     22311\n",
      "   macro avg       0.97      0.99      0.98     22311\n",
      "weighted avg       1.00      1.00      1.00     22311\n",
      "\n",
      "\n",
      "End report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           Ø       1.00      0.97      0.99     20589\n",
      "           ,       0.49      0.90      0.64       500\n",
      "           .       0.86      0.94      0.90       650\n",
      "           ?       0.92      0.97      0.95       572\n",
      "\n",
      "    accuracy                           0.97     22311\n",
      "   macro avg       0.82      0.95      0.87     22311\n",
      "weighted avg       0.98      0.97      0.97     22311\n",
      "\n",
      "\n",
      "Cap report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       lower       0.99      0.99      0.99     15241\n",
      "        init       0.96      0.98      0.97      4721\n",
      "         mix       0.98      0.82      0.90        68\n",
      "       upper       0.86      0.97      0.91       255\n",
      "\n",
      "    accuracy                           0.98     20285\n",
      "   macro avg       0.95      0.94      0.94     20285\n",
      "weighted avg       0.98      0.98      0.98     20285\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(model, dataloader_test, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hola que lindo dia que hace no te parece => Hola, que lindo, Dia, que hace, no te parece?\n"
     ]
    }
   ],
   "source": [
    "entrada = \"hola que lindo dia que hace no te parece\"\n",
    "print(f\"{entrada} => {predict_and_reconstruct(model, entrada, tokenizer, device, verbose=False)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba de control de Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "explicacion de del corro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frases = [\"¿QUE?\"]\n",
    "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-multilingual-cased\")\n",
    "\n",
    "train_loader = get_dataloader(frases, max_length=25, batch_size=1, device=device,tokenizer=tokenizer)\n",
    "\n",
    "model = PunctuationCapitalizationRNN(\n",
    "    bert_model=bert_model,\n",
    "    hidden_dim=64,\n",
    "    num_punct_start_classes=5,\n",
    "    num_punct_end_classes=5,\n",
    "    num_cap_classes=4\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)  # Alto LR\n",
    "\n",
    "criterion_punct_start = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "criterion_punct_end   = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "criterion_cap         = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "\n",
    "train(\n",
    "    model,\n",
    "    dataloader_train=train_loader,\n",
    "    dataloader_test=train_loader,\n",
    "    optimizer=optimizer,\n",
    "    criterion_start=criterion_punct_start,\n",
    "    criterion_end=criterion_punct_end,\n",
    "    criterion_cap=criterion_cap,\n",
    "    device=device,\n",
    "    epochs=200\n",
    ")\n",
    "\n",
    "entrada = \"que\"\n",
    "print(\"Predicción:\", predict_and_reconstruct(model, entrada, tokenizer, device))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model_rnn_tres_cabezas.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generacion CSV TP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.datautils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta a un archivo TXT con párrafos (una instancia por párrafo)\n",
    "ruta_txt = \"predict/prueba.txt\"\n",
    "\n",
    "# Ejecutar predicciones y guardar CSV\n",
    "df_predicciones = predicciones_TP(ruta_txt, model, tokenizer, device, max_length=128, verbose=True)\n",
    "\n",
    "# Mostrar las primeras filas del dataframe con las predicciones\n",
    "print(df_predicciones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
