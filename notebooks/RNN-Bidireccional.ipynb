{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fabro/Documents/uba/aprendizaje_automatico/Puntualizacion-Capitalizacion/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from utils.datautils import *\n",
    "from utils.MLutils import *\n",
    "from utils.resources import *\n",
    "from transformers import BertTokenizerFast\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertModel\n",
    "import unicodedata\n",
    "\n",
    "# linea que arregla algunos errores de loadeo de datasets\n",
    "# pip install --upgrade datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Procesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usando: cuda\n"
     ]
    }
   ],
   "source": [
    "linux = True\n",
    "device = None\n",
    "\n",
    "if linux:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "else:\n",
    "    device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "print(\"usando:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejericio b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Busqueda de fuentes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fuente 1: Conjunto de preguntas en espa;ol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se descargaron 5000 preguntas en Español.\n"
     ]
    }
   ],
   "source": [
    "questions, question_for_mixture = get_questions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fuente 2: Dataset provisto para Notebook 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se descargaron 997 oraciones en Español (del dataset del notebook 10).\n"
     ]
    }
   ],
   "source": [
    "oraciones_rnn = get_notebook_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fuente 3: Dataset sintetico generado con Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hay 1413 oraciones sintéticas.\n"
     ]
    }
   ],
   "source": [
    "oraciones_sinteticas = get_gemini_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fuente 4: Articulos de Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Argentina, oficialmente República Argentina,[a]\\u200b es un país soberano de América del Sur, ubicado en el extremo sur y sudeste de ese subcontinente.', 'Adopta la forma de gobierno republicana, democrática, representativa y federal.', 'Poseen Carta Magna, bandera y fuerzas de seguridad propias, el dominio de los recursos naturales circunscriptos en su territorio y delegan los poderes exclusivos al Gobierno Federal.', 'Hasta mediados del siglo XX, fue una de las economías más prósperas del mundo.', 'No obstante, es la segunda economía más importante de Sudamérica —detrás de Brasil— y la 24.º más grande del mundo por PIB nominal.']\n"
     ]
    }
   ],
   "source": [
    "frases_wikipedia = get_wikipedia_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fuente 5: Subtitulos de peliculas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Se extrajeron 947 frases completas y se guardaron en 'dialogos_esperando_la_carroza.json'\n",
      "✅ Frases extraídas y guardadas. Total: 947\n",
      "['No, es la televisión...', '¡Gran ciencia cambiar un pañal! Al final...', 'Por empezar dejá de hinchar... Ay, doña Elisa, no, no era por usted. Cómo... Oiga, le habla Elvira: ¿qué pasa con el agua? Hice ravioles, ¿quiere tragedia mayor? Ah, ¿usted también? ¡Qué casualidad! Bueno, mire, ¿me hace un favor? No la tire. Quiero decir, usted hierve sus ravioles y cuando estén listos me llama por teléfono y yo le mando a buscar el agua. Ay, gracias, es usted un amor. Yo hago puchero, ella hace puchero. Yo hago ravioles, ella hace ravioles, ¡Qué país!', 'Pero yo me acosté a las cuatro de la mañana.', 'Che: ¿por qué no ventilan los trapitos sucios en la azotea de su propia casa?', 'SI existe, pero doña Elisa. Yo no tengo la más mínima duda de que no existe otra cosa que el infierno.', 'Lo mandé a cambiar. Bastante me deprime comer los ravioles que hace ésta como para encima aguantarlo a él en camiseta.', 'Sí, tu suegra y tu madre.', 'La teta al Oscarclto, mamá Cora; una bananlta pisada y nada más. Una bananlta. Eh... Gracias.', 'Ah...']\n",
      "✅ Se extrajeron 1000 frases de Relatos Salvajes.\n"
     ]
    }
   ],
   "source": [
    "esperando_la_carroza, frases_relatos_salvajes = get_pelis_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fuente 6 (beta): Mixture de oraciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['¿Cuál es el estado civil de Pilar? La capital de Azerbaiyán, Bakú, es conocida como la ciudad de los vientos.',\n",
       " '¿Cómo se origina una enana blanca? ¿En qué se convertían ellas?',\n",
       " '¿A cuántos grados como máximo pueden estar las enanas blancas que podrían tener una área habitable? ¿Cuánto dinero se cree que se había recaudado con The Legend of Zelda: Ocarina of Time a finales de 1998 en América?',\n",
       " '¿Cómo se conoce en la actualidad África del Sudoeste? La consola Genesis de Sega era popular.',\n",
       " 'La ciudad de Leptis Magna en Libia fue una ciudad romana. ¿Dónde está siendo atendido Bah?']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cant_oraciones = len(oraciones_sinteticas)\n",
    "question_for_mixture = [re.sub(r'[\\\\\\(\\)!¡“]', '', unicodedata.normalize(\"NFC\", q).strip()) for q in question_for_mixture]\n",
    "oraciones_sinteticas = [re.sub(r'[\\\\\\(\\)!¡“]', '', unicodedata.normalize(\"NFC\", a).strip()) for a in oraciones_sinteticas]\n",
    "\n",
    "tanda_1 = question_for_mixture[:cant_oraciones]\n",
    "question_affirmation = [f\"{q} {a}\" for q, a in zip(tanda_1, oraciones_sinteticas)]\n",
    "\n",
    "tanda_2 = question_for_mixture[cant_oraciones:2*cant_oraciones]\n",
    "affirmation_question = [f\"{a} {q}\" for q, a in zip(tanda_2, oraciones_sinteticas)]\n",
    "\n",
    "tanda_3 = question_for_mixture[2*cant_oraciones:3*cant_oraciones]\n",
    "tanda_3_shuffled = random.sample(tanda_3, len(tanda_3))\n",
    "question_question = [f\"{q} {p}\" for q, p in zip(tanda_3, tanda_3_shuffled)]\n",
    "\n",
    "mixtures = question_affirmation + affirmation_question + question_question\n",
    "\n",
    "random.sample(mixtures, 5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Juntamos las fuentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad total de oraciones: 20244\n",
      "Cantidad de oraciones de preguntas: 5000\n",
      "Cantidad de oraciones en espa;ol de hugging face: 997\n",
      "Cantidad de oraciones sintéticas: 1413\n",
      "Cantidad de oraciones de Wikipedia: 6648\n",
      "Cantidad de oraciones de Esperando la carroza: 947\n",
      "Cantidad de oraciones de Relatos Salvajes: 1000\n",
      "Cantidad de oraciones Compuestas: 4239\n",
      "Algunas oraciones aleatorias:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Bebí una Coca-Cola en el bar.',\n",
       " 'Adobe ofrece descuentos para los estudiantes.',\n",
       " 'Mi cámara digital es de la marca Canon. ¿Qué fenómeno meteorológico amenaza al litoral oriental norteamericano?',\n",
       " '¿Cuál es la función del INEGI?',\n",
       " '¿Cuáles son las características del clima mediterráneo continentalizado?']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oraciones_raw = questions + oraciones_rnn + oraciones_sinteticas + frases_wikipedia + esperando_la_carroza  + frases_relatos_salvajes + mixtures\n",
    "\n",
    "print('Cantidad total de oraciones:',len(oraciones_raw))\n",
    "print('Cantidad de oraciones de preguntas:',len(questions))\n",
    "print('Cantidad de oraciones en espa;ol de hugging face:',len(oraciones_rnn))\n",
    "print('Cantidad de oraciones sintéticas:',len(oraciones_sinteticas))\n",
    "print('Cantidad de oraciones de Wikipedia:',len(frases_wikipedia))\n",
    "print('Cantidad de oraciones de Esperando la carroza:',len(esperando_la_carroza))\n",
    "print('Cantidad de oraciones de Relatos Salvajes:',len(frases_relatos_salvajes))\n",
    "print('Cantidad de oraciones Compuestas:',len(mixtures))\n",
    "\n",
    "print(\"Algunas oraciones aleatorias:\")\n",
    "random.sample(oraciones_raw, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separamos en conjuntos de `train` y `test` con el tokenizer de `BERT`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19231\n",
      "1013\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-multilingual-cased\")\n",
    "\n",
    "train_sents, test_sents = train_test_split(oraciones_raw, test_size=0.05, random_state=42)\n",
    "\n",
    "dataloader_train = get_dataloader(oraciones_raw=oraciones_raw, max_length=64, batch_size=64, device=device, tokenizer=tokenizer)\n",
    "dataloader_test = get_dataloader(oraciones_raw=test_sents, max_length=64, batch_size=64, device=device, tokenizer=tokenizer)\n",
    "\n",
    "print(len(train_sents))\n",
    "print(len(test_sents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 180,944,905\n",
      "Trainable parameters: 17,857,801\n"
     ]
    }
   ],
   "source": [
    "from train.PunctuationCapitalizationRNNBidirectional import PunctuationCapitalizationRNNBidirectional\n",
    "\n",
    "model_name = \"bert-base-multilingual-cased\"\n",
    "bert_model = BertModel.from_pretrained(model_name)\n",
    "\n",
    "bert_embeddings = bert_model.embeddings.word_embeddings\n",
    "for param in bert_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "N = 2\n",
    "for layer in bert_model.encoder.layer[-N:]:\n",
    "    for param in layer.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "for param in bert_model.pooler.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "\n",
    "model = PunctuationCapitalizationRNNBidirectional(\n",
    "    bert_model = bert_model,\n",
    "    hidden_dim=256,\n",
    "    num_punct_classes=len(PUNCT_TAGS),\n",
    "    num_cap_classes=len(CAP_TAGS)\n",
    ").to(device)\n",
    "\n",
    "ckpt = torch.load(\"model_bidirec.pt\", map_location=device)\n",
    "# si guardaste state_dict puro\n",
    "if isinstance(ckpt, dict) and \"model_state_dict\" not in ckpt:\n",
    "    model.load_state_dict(ckpt)\n",
    "\n",
    "# si guardaste un dict con más cosas (epoch, optim, etc.)\n",
    "elif \"model_state_dict\" in ckpt:\n",
    "    model.load_state_dict(ckpt[\"model_state_dict\"])\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Train Loss: 0.2961\n",
      "Epoch 2 | Train Loss: 0.2634\n",
      "Epoch 3 | Train Loss: 0.2460\n",
      "Epoch 4 | Train Loss: 0.2331\n",
      "Epoch 5 | Train Loss: 0.2244\n",
      "Epoch 6 | Train Loss: 0.2134\n",
      "Epoch 7 | Train Loss: 0.2084\n",
      "Epoch 8 | Train Loss: 0.1982\n",
      "Epoch 9 | Train Loss: 0.1921\n",
      "Epoch 10 | Train Loss: 0.1851\n",
      "Epoch 11 | Train Loss: 0.1798\n",
      "Epoch 12 | Train Loss: 0.1729\n",
      "Epoch 13 | Train Loss: 0.1673\n",
      "Epoch 14 | Train Loss: 0.1605\n",
      "Epoch 15 | Train Loss: 0.1561\n",
      "Epoch 16 | Train Loss: 0.1516\n",
      "Epoch 17 | Train Loss: 0.1474\n",
      "Epoch 18 | Train Loss: 0.1418\n",
      "Epoch 19 | Train Loss: 0.1377\n",
      "Epoch 20 | Train Loss: 0.1340\n"
     ]
    }
   ],
   "source": [
    "punct_weights_tensor, cap_weights_tensor = compute_class_weights(\n",
    "    dataloader_train,\n",
    "    num_punct_classes=len(PUNCT_TAGS),\n",
    "    num_cap_classes=len(CAP_TAGS),\n",
    "    device=device,\n",
    "    beta=0.7\n",
    ")\n",
    "\n",
    "criterion_punct = nn.CrossEntropyLoss(ignore_index=-100, weight=punct_weights_tensor)\n",
    "criterion_cap   = nn.CrossEntropyLoss(ignore_index=-100, weight=cap_weights_tensor)\n",
    "\n",
    "trainable_params = [\n",
    "    p for p in bert_model.parameters() if p.requires_grad\n",
    "] + list(model.projection.parameters()) \\\n",
    "  + list(model.rnn.parameters()) \\\n",
    "  + list(model.punct_classifier.parameters()) \\\n",
    "  + list(model.cap_classifier.parameters())\n",
    "\n",
    "optimizer = torch.optim.AdamW(trainable_params, lr=2e-5)\n",
    "\n",
    "train(model, dataloader_train=dataloader_train, dataloader_test=dataloader_test,optimizer=optimizer, criterion_punct=criterion_punct, criterion_cap = criterion_cap, device=device, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(model, dataloader_test, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quiero aprender a programar en Python. Conocés algún curso.\n"
     ]
    }
   ],
   "source": [
    "entrada = \"quiero aprender a programar en python conocés algún curso\"\n",
    "print(f\"{predict_and_reconstruct(model, entrada, tokenizer, device, verbose=False)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model_bidirec_more_data.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
