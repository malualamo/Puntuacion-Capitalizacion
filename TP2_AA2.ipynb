{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KIQ-8H9RzShl"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/fabro/Documents/uba/aprendizaje_automatico/aa/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import unicodedata\n",
        "import re\n",
        "import random\n",
        "from datasets import load_dataset\n",
        "from collections import defaultdict\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import Counter\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ife5qyKlodXD"
      },
      "source": [
        "# Ejercicio a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ujDeN9474GId"
      },
      "outputs": [],
      "source": [
        "# linea que arregla algunos errores de loadeo de datasets\n",
        "!pip install --upgrade datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Se descargaron 5000 preguntas en Español.\n"
          ]
        }
      ],
      "source": [
        "DATA_URLS = {\n",
        "    \"train\": \"https://huggingface.co/datasets/PlanTL-GOB-ES/SQAC/resolve/main/train.json\",\n",
        "    \"dev\":   \"https://huggingface.co/datasets/PlanTL-GOB-ES/SQAC/resolve/main/dev.json\",\n",
        "    \"test\":  \"https://huggingface.co/datasets/PlanTL-GOB-ES/SQAC/resolve/main/test.json\",\n",
        "}\n",
        "\n",
        "raw = load_dataset(\n",
        "    \"json\",\n",
        "    data_files=DATA_URLS,\n",
        "    field=\"data\",\n",
        ")\n",
        "\n",
        "questions = []\n",
        "\n",
        "for i in range(0, len(raw[\"train\"])):\n",
        "  for p in raw[\"train\"][i]['paragraphs']:\n",
        "    p_questions = [qas['question'] for qas in p['qas']]\n",
        "    questions += p_questions\n",
        "\n",
        "N_QUESTIONS = 5000\n",
        "questions = questions[:N_QUESTIONS]\n",
        "print(f\"Se descargaron {len(questions)} preguntas en Español.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Se descargaron 997 oraciones en Español (del dataset del notebook 10).\n"
          ]
        }
      ],
      "source": [
        "dataset_rnn = load_dataset(\"google/wmt24pp\", \"en-es_MX\", split=\"train\")\n",
        "oraciones_rnn = dataset_rnn['target'][1:]\n",
        "\n",
        "print(f\"Se descargaron {len(oraciones_rnn)} oraciones en Español (del dataset del notebook 10).\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hay 1413 oraciones sintéticas.\n"
          ]
        }
      ],
      "source": [
        "oraciones_sinteticas = []\n",
        "import json\n",
        "with open('./datasets.json', 'r') as file:\n",
        "  data = json.load(file)\n",
        "\n",
        "oraciones_sinteticas = data['otros'] + data['marcas']\n",
        "print(f\"Hay {len(oraciones_sinteticas)} oraciones sintéticas.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "LTdR0E0A9Pz6"
      },
      "outputs": [],
      "source": [
        "oraciones_raw = oraciones_rnn + questions + oraciones_sinteticas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "wiQQTFLbC4TP"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "construido un vocabulario de 14423 palabras.\n"
          ]
        }
      ],
      "source": [
        "def build_vocabulario(oraciones):\n",
        "    text = \" \".join(oraciones)\n",
        "    text = unicodedata.normalize(\"NFD\", text)\n",
        "    text = text.encode(\"ascii\", \"ignore\").decode(\"utf-8\")\n",
        "    words = re.findall(r\"[A-Za-z]+\", text.lower())\n",
        "\n",
        "    unique = dict.fromkeys(words)\n",
        "    return {word: idx for idx, word in enumerate(unique)}\n",
        "\n",
        "word_to_index = build_vocabulario(oraciones_raw)\n",
        "print(f\"construido un vocabulario de {len(word_to_index)} palabras.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Funciones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "gm-vu84VG2pQ"
      },
      "outputs": [],
      "source": [
        "def _tiene_acento(word):\n",
        "    return any(unicodedata.category(c) == 'Mn' for c in unicodedata.normalize('NFD', word))\n",
        "\n",
        "def _get_capitalization_type(word):\n",
        "    if not word or word.islower(): return 0\n",
        "    if word.istitle(): return 1\n",
        "    if word.isupper(): return 3\n",
        "    if any(c.isupper() for c in word[1:]): return 2\n",
        "    return 0\n",
        "\n",
        "def _get_punctuation_type(sentence, start, end):\n",
        "    before = sentence[start - 1] if start > 0 else \"\"\n",
        "    after = sentence[end] if end < len(sentence) else \"\"\n",
        "    has_apertura = (before in '¿¡')\n",
        "    has_cierre = (after in '?!')\n",
        "    if has_apertura and has_cierre: return 0\n",
        "    if has_apertura: return 1\n",
        "    if has_cierre: return 2\n",
        "    if '.' in (before, after): return 3\n",
        "    if ',' in (before, after): return 4\n",
        "    return 5\n",
        "\n",
        "def procesar_oracion_sintetizado(sentence, word_to_index):\n",
        "    matches = list(re.finditer(r'\\b\\w+\\b', sentence))\n",
        "    if not matches:\n",
        "        return []\n",
        "\n",
        "    total_words = len(matches)\n",
        "    cleaned_words = [unicodedata.normalize('NFD', m.group(0)).encode('ascii', 'ignore').decode('utf-8').lower() for m in matches]\n",
        "    tokens = [word_to_index.get(cw, -1) for cw in cleaned_words]\n",
        "\n",
        "    return [{\n",
        "        \"word\": cleaned_words[i],\n",
        "        \"token\": tokens[i],\n",
        "        \"prev_token\": tokens[i - 1] if i > 0 else -1,\n",
        "        \"next_token\": tokens[i + 1] if i < total_words - 1 else -1,\n",
        "        \"has_accent\": 1 if _tiene_acento(match.group(0)) else 0,\n",
        "        \"position\": round(i / (total_words - 1), 2) if total_words > 1 else 0.0,\n",
        "        \"punctuation_type\": _get_punctuation_type(sentence, match.start(), match.end()),\n",
        "        \"capitalization_type\": _get_capitalization_type(match.group(0)),\n",
        "    } for i, match in enumerate(matches)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 284,
      "metadata": {
        "id": "UDI_lhDtWg3h"
      },
      "outputs": [],
      "source": [
        "def reconstruct_input(oracion, clf_cap, clf_punc):\n",
        "    processed = procesar_oracion_sintetizado(oracion, word_to_index)\n",
        "    # , item['position']\n",
        "    X = [\n",
        "        [item['token'], item['prev_token'], item['next_token'], item['has_accent']]\n",
        "        for item in processed\n",
        "    ]\n",
        "    caps = clf_cap.predict(X)\n",
        "    puncs = clf_punc.predict(X)\n",
        "\n",
        "    def cap2(word):\n",
        "        return (word[0].upper() + word[1:-1].lower() + word[-1].upper()) if len(word) > 1 else word.upper()\n",
        "\n",
        "    cap_funcs = {\n",
        "        0: str.lower,\n",
        "        1: str.capitalize,\n",
        "        2: cap2,\n",
        "        3: str.upper,\n",
        "    }\n",
        "\n",
        "    punc_templates = {\n",
        "        0: lambda w: f\"¿{w}?\",\n",
        "        1: lambda w: f\"¿{w}\",\n",
        "        2: lambda w: f\"{w}?\",\n",
        "        3: lambda w: f\"{w}.\",\n",
        "        4: lambda w: f\"{w},\",\n",
        "    }\n",
        "\n",
        "    palabras = []\n",
        "    for item, c, p in zip(processed, caps, puncs):\n",
        "        word = cap_funcs.get(c, lambda w: w)(item['word'])\n",
        "        word = punc_templates.get(p, lambda w: w)(word)\n",
        "        palabras.append(word)\n",
        "\n",
        "    return \" \".join(palabras)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 285,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "id": "DsODtHV7meaF",
        "outputId": "a02eba6f-ef7f-4b6f-d6e8-fd19b2e3015b"
      },
      "outputs": [],
      "source": [
        "def undersample_classes(X, y, targets, seed=None):\n",
        "    if seed is not None:\n",
        "        random.seed(seed)\n",
        "\n",
        "    groups = defaultdict(list)\n",
        "    for xi, yi in zip(X, y):\n",
        "        groups[yi].append((xi, yi))\n",
        "\n",
        "    new_pairs = []\n",
        "    for cls, items in groups.items():\n",
        "        if cls in targets:\n",
        "            n = min(len(items), targets[cls])\n",
        "            new_pairs.extend(random.sample(items, n))\n",
        "        else:\n",
        "            new_pairs.extend(items)\n",
        "\n",
        "    random.shuffle(new_pairs)\n",
        "    X_new, y_new = zip(*new_pairs)\n",
        "    return list(X_new), list(y_new)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Armamos el dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 286,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0w_1QYnmG86b",
        "outputId": "948065b5-7d51-4d6b-c68e-43c829f28737"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tamaño de dataset: 91365\n"
          ]
        }
      ],
      "source": [
        "curated_dataset = []\n",
        "\n",
        "for sentence in oraciones_raw:\n",
        "    curated_dataset.append(procesar_oracion_sintetizado(sentence, word_to_index))\n",
        "\n",
        "master_dataset = [item for sublist in curated_dataset for item in sublist]\n",
        "\n",
        "print(f\"Tamaño de dataset: {len(master_dataset)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## RF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 287,
      "metadata": {
        "id": "sieTZcSAWAqE"
      },
      "outputs": [],
      "source": [
        "# , item['position']\n",
        "X = [[item['token'], item['prev_token'], item['next_token'], item['has_accent']] for item in master_dataset]\n",
        "\n",
        "y_capitalization = [item['capitalization_type'] for item in master_dataset]\n",
        "y_punctuation = [item['punctuation_type'] for item in master_dataset]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 288,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RnX3L2fOkWYY",
        "outputId": "f601415e-4913-471f-d942-c1134d7c07c1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Counter({5: 20000, 1: 7447, 2: 5475, 3: 3277, 4: 2259, 0: 48})"
            ]
          },
          "execution_count": 288,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# manejo desbalanceo en puntuacion\n",
        "\n",
        "targets = {5: 20000, 1: 10000, 2: 10000}\n",
        "X_punctuation, y_punctuation = undersample_classes(X, y_punctuation, targets, seed=42)\n",
        "\n",
        "Counter(y_punctuation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 289,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Counter({0: 50000, 1: 17009, 3: 917, 2: 178})"
            ]
          },
          "execution_count": 289,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# manejo desbalanceo en capitalizacion\n",
        "targets = {0: 50000}\n",
        "X_cap, y_cap = undersample_classes(X, y_capitalization, targets, seed=42)\n",
        "\n",
        "\n",
        "Counter(y_cap)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 290,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "OW215G2YWZdk",
        "outputId": "3f1d97e5-96ab-4f47-e9e8-78b4bdaec778"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8939138095587695\n"
          ]
        }
      ],
      "source": [
        "# ARBOL PARA CAPITALIZACION\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_cap, y_cap, test_size=0.2, random_state=42)\n",
        "\n",
        "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "score = clf.score(X_test, y_test)\n",
        "print(f\"Accuracy: {score}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 291,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "q-rgRUjZomVt",
        "outputId": "57c8fdf2-e067-4be6-cec1-2dd6eaad4902"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8631524279407946\n"
          ]
        }
      ],
      "source": [
        "# ARBOL PARA PUNTUACION\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_punctuation, y_punctuation, test_size=0.2, random_state=42)\n",
        "clf_punctuation = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "clf_punctuation.fit(X_train, y_train)\n",
        "\n",
        "score = clf_punctuation.score(X_test, y_test)\n",
        "print(f\"Accuracy: {score}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 307,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8J3flTvXZhzv",
        "outputId": "4f837ced-4ff7-4592-9ace-e9f74e8de27c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "chau. ¿llamaron de la NASA para ver como sacar plata de PaypaL.\n"
          ]
        }
      ],
      "source": [
        "resultado = reconstruct_input(\"chau llamaron de la nasa para ver cómo sacar plata de paypal\", clf, clf_punctuation)\n",
        "print(resultado)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Ejericio b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device = cuda:0\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cpu')\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "\n",
        "torch.set_default_device(device)\n",
        "print(f\"Using device = {torch.get_default_device()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class SimpleAttention(nn.Module):\n",
        "    def __init__(self, feature_dim):\n",
        "        super(SimpleAttention, self).__init__()\n",
        "        self.feature_dim = feature_dim\n",
        "        self.query_proj = nn.Linear(feature_dim, feature_dim)\n",
        "        self.key_proj = nn.Linear(feature_dim, feature_dim)\n",
        "        self.value_proj = nn.Linear(feature_dim, feature_dim)\n",
        "\n",
        "    def forward(self, query, keys, values):\n",
        "        q = self.query_proj(query)\n",
        "        k = self.key_proj(keys)\n",
        "        v = self.value_proj(values)\n",
        "\n",
        "        d_k = self.feature_dim\n",
        "        attention_scores = (q @ k.transpose(-2, -1)) / torch.sqrt(d_k)\n",
        "        attention_weights = F.softmax(attention_scores, dim=-1)\n",
        "\n",
        "        context_vector = torch.matmul(attention_weights, v)\n",
        "        return context_vector, attention_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CapitalizationRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(CapitalizationRNN, self).__init__()\n",
        "\n",
        "        self.model_name = \"bert-base-multilingual-cased\"\n",
        "        self.tokenizer = BertTokenizer.from_pretrained(self.model_name)\n",
        "        self.bert = BertModel.from_pretrained(self.model_name)\n",
        "        self.bert.eval()\n",
        "\n",
        "        self.rnn = nn.LSTM(\n",
        "            input_size=self.bert.config.hidden_size,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=4,\n",
        "            batch_first=True,\n",
        "            bidirectional=False\n",
        "        )\n",
        "\n",
        "        self.attention = SimpleAttention(hidden_size)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, input_ids):\n",
        "        batch_size, seq_len = input_ids.size()\n",
        "        device = input_ids.device\n",
        "\n",
        "        with torch.no_grad():\n",
        "            bert_out = self.bert(input_ids, attention_mask=mask)\n",
        "            embeddings = bert_out.last_hidden_state\n",
        "        h0 = torch.zeros(4, batch_size, self.rnn.hidden_size).to(device)\n",
        "        c0 = torch.zeros(4, batch_size, self.rnn.hidden_size).to(device)\n",
        "\n",
        "        rnn_out, _ = self.rnn(embeddings, (h0, c0))\n",
        "\n",
        "        context_out, _ = self.attention(rnn_out, rnn_out, rnn_out)\n",
        "\n",
        "        out = self.fc(context_out) \n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CapitalizationDataset(Dataset):\n",
        "    def __init__(self, tokenized_sentences, labels, tokenizer, pad_label=-100):\n",
        "        \"\"\"\n",
        "        tokenized_sentences: lista de listas de tokens BERT\n",
        "        labels: lista de listas de ints (misma longitud que cada oración)\n",
        "        \"\"\"\n",
        "        self.tokenizer = tokenizer\n",
        "        self.sentences = tokenized_sentences\n",
        "        self.labels = labels\n",
        "        self.pad_token_id = tokenizer.pad_token_id\n",
        "        self.pad_label = pad_label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sentences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        tokens = self.sentences[idx]\n",
        "        label_seq = self.labels[idx]\n",
        "\n",
        "        input_ids = self.tokenizer.convert_tokens_to_ids(tokens)\n",
        "        return input_ids, label_seq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def collate_batch(batch, pad_token_id, pad_label=-100):\n",
        "    input_ids, labels = zip(*batch)\n",
        "    max_len = max(len(x) for x in input_ids)\n",
        "\n",
        "    padded_ids = []\n",
        "    padded_labels = []\n",
        "\n",
        "    for ids, lbls in zip(input_ids, labels):\n",
        "        pad_len = max_len - len(ids)\n",
        "        padded_ids.append(ids + [pad_token_id] * pad_len)\n",
        "        padded_labels.append(lbls + [pad_label] * pad_len)\n",
        "\n",
        "    return torch.tensor(padded_ids), torch.tensor(padded_labels)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Armo el dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [],
      "source": [
        "tokenized_sentences = []\n",
        "labels_list = []\n",
        "\n",
        "for oracion in oraciones_raw:\n",
        "    if len(oracion.split(\" \")) > 6:\n",
        "        continue\n",
        "    palabras = oracion.split()\n",
        "    tokens_por_palabra = [tokenizer.tokenize(palabra) for palabra in palabras]\n",
        "    cap_labels = [_get_capitalization_type(palabra) for palabra in palabras]\n",
        "\n",
        "    tokenized = [token for sublist in tokens_por_palabra for token in sublist]\n",
        "    labels = [label for label, tokens in zip(cap_labels, tokens_por_palabra) for _ in tokens]\n",
        "\n",
        "    if len(tokenized) > 512:\n",
        "        print(f\"⚠️ Oración demasiado larga (descartada): {oracion}\")\n",
        "        continue\n",
        "\n",
        "    minority_ratio = sum(lbl != 0 for lbl in cap_labels) / len(cap_labels)\n",
        "\n",
        "    tokenized_sentences.append(tokenized)\n",
        "    labels_list.append(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Label counts: Counter({0: 9286, 1: 7568, 2: 412, 3: 344})\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "import torch\n",
        "\n",
        "# Aplanar todas las etiquetas\n",
        "all_labels = [label for seq in labels_list for label in seq]\n",
        "counts = Counter(all_labels)\n",
        "print(\"Label counts:\", counts)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "sqrt(): argument 'input' (position 1) must be Tensor, not int",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[86]\u001b[39m\u001b[32m, line 57\u001b[39m\n\u001b[32m     54\u001b[39m input_ids = input_ids.to(device)          \u001b[38;5;66;03m# [B, S]\u001b[39;00m\n\u001b[32m     55\u001b[39m targets   = targets.to(device)            \u001b[38;5;66;03m# [B, S]\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m logits = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m)\u001b[49m                 \u001b[38;5;66;03m# [B, S, C]\u001b[39;00m\n\u001b[32m     58\u001b[39m logits = logits.view(-\u001b[32m1\u001b[39m, \u001b[32m4\u001b[39m)               \u001b[38;5;66;03m# [B*S, C]\u001b[39;00m\n\u001b[32m     59\u001b[39m targets = targets.view(-\u001b[32m1\u001b[39m)                \u001b[38;5;66;03m# [B*S]\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/uba/aprendizaje_automatico/aa/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/uba/aprendizaje_automatico/aa/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[50]\u001b[39m\u001b[32m, line 33\u001b[39m, in \u001b[36mCapitalizationRNN.forward\u001b[39m\u001b[34m(self, input_ids)\u001b[39m\n\u001b[32m     29\u001b[39m c0 = torch.zeros(\u001b[32m4\u001b[39m, batch_size, \u001b[38;5;28mself\u001b[39m.rnn.hidden_size).to(device)\n\u001b[32m     31\u001b[39m rnn_out, _ = \u001b[38;5;28mself\u001b[39m.rnn(embeddings, (h0, c0))\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m context_out, _ = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrnn_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrnn_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrnn_out\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     35\u001b[39m out = \u001b[38;5;28mself\u001b[39m.fc(context_out) \n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/uba/aprendizaje_automatico/aa/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/uba/aprendizaje_automatico/aa/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[85]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mSimpleAttention.forward\u001b[39m\u001b[34m(self, query, keys, values)\u001b[39m\n\u001b[32m     14\u001b[39m v = \u001b[38;5;28mself\u001b[39m.value_proj(values)\n\u001b[32m     16\u001b[39m d_k = \u001b[38;5;28mself\u001b[39m.feature_dim\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m attention_scores = (q @ k.transpose(-\u001b[32m2\u001b[39m, -\u001b[32m1\u001b[39m)) / \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43md_k\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m attention_weights = F.softmax(attention_scores, dim=-\u001b[32m1\u001b[39m)\n\u001b[32m     20\u001b[39m context_vector = torch.matmul(attention_weights, v)\n",
            "\u001b[31mTypeError\u001b[39m: sqrt(): argument 'input' (position 1) must be Tensor, not int"
          ]
        }
      ],
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
        "dataset = CapitalizationDataset(tokenized_sentences, labels_list, tokenizer)\n",
        "dataloader = DataLoader(\n",
        "    dataset,\n",
        "    batch_size=16,\n",
        "    shuffle=True,\n",
        "    generator=torch.Generator(device=device),\n",
        "    collate_fn=lambda x: collate_batch(x, tokenizer.pad_token_id)\n",
        ")\n",
        "\n",
        "model = CapitalizationRNN(hidden_size=128, output_size=4)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Definición de focal loss\n",
        "def focal_loss(inputs, targets, alpha, gamma=2, ignore_index=-100):\n",
        "    \"\"\"\n",
        "    inputs: Tensor [N, C] logits sin softmax\n",
        "    targets: Tensor [N] con labels en {0,…,C-1} o ignore_index\n",
        "    alpha: Tensor [C] pesos por clase\n",
        "    gamma: coeficiente de focalización\n",
        "    \"\"\"\n",
        "    # Calculamos la CE por elemento (sin reducción)\n",
        "    ce = F.cross_entropy(inputs, targets,\n",
        "                         reduction='none',\n",
        "                         weight=alpha,\n",
        "                         ignore_index=ignore_index)\n",
        "    # Probabilidad del target\n",
        "    p_t = torch.exp(-ce)\n",
        "    # Focal term\n",
        "    loss = (1 - p_t)**gamma * ce\n",
        "    # Ignoramos posiciones de padding en el promedio\n",
        "    valid_mask = (targets != ignore_index).float()\n",
        "    return (loss * valid_mask).sum() / valid_mask.sum()\n",
        "\n",
        "# — Antes de entrenar, calculas alpha (pesos de clase) como ya tienes:\n",
        "all_labels = [lab for seq in labels_list for lab in seq]\n",
        "counts = Counter(all_labels)\n",
        "total = sum(counts.values())\n",
        "eps = 1e-6\n",
        "class_weights = [ total / (counts[i] + eps) for i in range(4) ]\n",
        "alpha = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
        "\n",
        "# Reemplazamos criterion y scheduler si lo quisieras:\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "for epoch in range(1, 41):\n",
        "    model.train()\n",
        "    epoch_loss = 0.0\n",
        "\n",
        "    for input_ids, targets in dataloader:\n",
        "        input_ids = input_ids.to(device)          # [B, S]\n",
        "        targets   = targets.to(device)            # [B, S]\n",
        "\n",
        "        logits = model(input_ids)                 # [B, S, C]\n",
        "        logits = logits.view(-1, 4)               # [B*S, C]\n",
        "        targets = targets.view(-1)                # [B*S]\n",
        "\n",
        "        loss = focal_loss(logits, targets,\n",
        "                          alpha=alpha,\n",
        "                          gamma=2,\n",
        "                          ignore_index=-100)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch:02d} — Loss: {epoch_loss/len(dataloader):.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [],
      "source": [
        "def predict_capitalization(model, sentence, tokenizer, device):\n",
        "    model.eval()\n",
        "    words = sentence.strip().split()\n",
        "    \n",
        "    tokens_per_word = [tokenizer.tokenize(word) for word in words]\n",
        "    flat_tokens = [tok for toks in tokens_per_word for tok in toks]\n",
        "\n",
        "    input_ids = tokenizer.convert_tokens_to_ids(flat_tokens)\n",
        "    input_tensor = torch.tensor([input_ids], dtype=torch.long).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_tensor)\n",
        "        probs = torch.round(torch.softmax(outputs, dim=-1)).squeeze(0)\n",
        "        print(f\"outputs: {probs}\")\n",
        "        predictions = torch.argmax(outputs, dim=-1).squeeze(0).tolist()\n",
        "\n",
        "    index = 0\n",
        "    result = []\n",
        "    for word, toks in zip(words, tokens_per_word):\n",
        "        length = len(toks)\n",
        "        pred = predictions[index:index+length]\n",
        "        most_common = max(set(pred), key=pred.count)\n",
        "        result.append((word, most_common))\n",
        "        index += length\n",
        "\n",
        "    return result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "outputs: tensor([[1., 0., 0., 0.],\n",
            "        [1., 0., 0., 0.],\n",
            "        [1., 0., 0., 0.],\n",
            "        [1., 0., 0., 0.],\n",
            "        [1., 0., 0., 0.],\n",
            "        [1., 0., 0., 0.],\n",
            "        [1., 0., 0., 0.],\n",
            "        [1., 0., 0., 0.],\n",
            "        [1., 0., 0., 0.]], device='cuda:0')\n",
            "españa: 0\n",
            "es: 0\n",
            "un: 0\n",
            "país: 0\n",
            "de: 0\n",
            "europa: 0\n"
          ]
        }
      ],
      "source": [
        "sample = \"españa es un país de europa\"\n",
        "preds = predict_capitalization(model, sample, tokenizer, device)\n",
        "for word, label in preds:\n",
        "    print(f\"{word}: {label}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.05      0.73      0.09        26\n",
            "           1       0.17      0.92      0.28        25\n",
            "           2       0.00      0.00      0.00         0\n",
            "           3       1.00      0.92      0.96      6702\n",
            "\n",
            "    accuracy                           0.92      6753\n",
            "   macro avg       0.30      0.64      0.33      6753\n",
            "weighted avg       0.99      0.92      0.95      6753\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/fabro/Documents/uba/aprendizaje_automatico/aa/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
            "/home/fabro/Documents/uba/aprendizaje_automatico/aa/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
            "/home/fabro/Documents/uba/aprendizaje_automatico/aa/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
            "/home/fabro/Documents/uba/aprendizaje_automatico/aa/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
            "/home/fabro/Documents/uba/aprendizaje_automatico/aa/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
            "/home/fabro/Documents/uba/aprendizaje_automatico/aa/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
            "/home/fabro/Documents/uba/aprendizaje_automatico/aa/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
            "/home/fabro/Documents/uba/aprendizaje_automatico/aa/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
            "/home/fabro/Documents/uba/aprendizaje_automatico/aa/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "all_preds = []\n",
        "all_targets = []\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for input_ids, targets in dataloader:\n",
        "        input_ids, targets = input_ids.to(device), targets.to(device)\n",
        "        outputs = model(input_ids)\n",
        "        preds = torch.argmax(outputs, dim=-1)\n",
        "\n",
        "        # Aplanar y filtrar padding\n",
        "        flat_preds = preds.view(-1).cpu().tolist()\n",
        "        flat_targets = targets.view(-1).cpu().tolist()\n",
        "        for p, t in zip(flat_preds, flat_targets):\n",
        "            if t != -100:\n",
        "                all_preds.append(p)\n",
        "                all_targets.append(t)\n",
        "\n",
        "# Mostrar reporte\n",
        "print(classification_report(all_targets, all_preds, labels=[0, 1, 2, 3]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yuaIvB-Gx5q9"
      },
      "source": [
        "# By Flor (GPT)\n",
        "\n",
        "GPT lo limpió un poco y lo completó con lo que faltaba...."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gcDj_abWyBV2"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer, BertModel\n",
        "import unicodedata, re, random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, confusion_matrix\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ChjBmpOIyDMw"
      },
      "outputs": [],
      "source": [
        "# ## 2. Load Tokenizer and (optional) BERT Embeddings\n",
        "model_name = \"bert-base-multilingual-cased\"\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "# (Later: extract embeddings if desired)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ndIXm2jRyFfc"
      },
      "outputs": [],
      "source": [
        "# ## 3. Text Cleaning and Feature Extraction Functions\n",
        "\n",
        "def limpiar_texto(texto):\n",
        "    texto = texto.replace('\"', '').replace(\"'\", '')\n",
        "    texto = re.sub(r'FIN[\\s\\S]*$', '', texto.strip())\n",
        "    return texto.strip()\n",
        "\n",
        "# Detect accent\n",
        "\n",
        "def tiene_acento(word):\n",
        "    w = re.sub(r\"ñ\", \"n\", word)\n",
        "    normalized = unicodedata.normalize(\"NFD\", w)\n",
        "    cleaned = re.sub(r\"[^\\w\\s]\", \"\", normalized)\n",
        "    return w != cleaned\n",
        "\n",
        "# Capitalization type\n",
        "\n",
        "def get_capitalization_type(word):\n",
        "    if word.islower(): return 0\n",
        "    elif word.istitle(): return 1\n",
        "    elif word.isupper(): return 3\n",
        "    elif any(c.isupper() for c in word[1:]): return 2\n",
        "    else: return 0\n",
        "\n",
        "# Punctuation type around token\n",
        "\n",
        "def get_punctuation_type(sentence, start, end):\n",
        "    before = sentence[start-1] if start > 0 else ''\n",
        "    after  = sentence[end]     if end < len(sentence) else ''\n",
        "    if before=='¿' and after=='?': return 0\n",
        "    if before=='¿':                return 1\n",
        "    if after=='?':                 return 2\n",
        "    if before=='.' or after=='.':  return 3\n",
        "    if before==',' or after==',':  return 4\n",
        "    return 5\n",
        "\n",
        "# Process one sentence into list of feature dicts\n",
        "\n",
        "def procesar_oracion(sentence, word_to_index):\n",
        "    original = [(m.group(), m.start(), m.end()) for m in re.finditer(r'\\b\\w+\\b', sentence)]\n",
        "    cleaned = unicodedata.normalize(\"NFD\", sentence).encode(\"ascii\",\"ignore\").decode(\"utf-8\")\n",
        "    cleaned = re.sub(r\"[^a-zA-Z\\s]+\", \"\", cleaned).lower().strip()\n",
        "    words = cleaned.split()\n",
        "    N = len(words)\n",
        "    output = []\n",
        "    used = set()\n",
        "    for i, w in enumerate(words):\n",
        "        token_id = word_to_index.get(w, -1)\n",
        "        prev_id  = word_to_index.get(words[i-1], -1) if i>0 else -1\n",
        "        next_id  = word_to_index.get(words[i+1], -1) if i<N-1 else -1\n",
        "        punct_type = 5\n",
        "        orig_word = ''\n",
        "        for j, (ow, s, e) in enumerate(original):\n",
        "            if j in used: continue\n",
        "            ow_clean = unicodedata.normalize(\"NFD\", ow).encode(\"ascii\",\"ignore\").decode(\"utf-8\")\n",
        "            ow_clean = re.sub(r\"[^\\w\\s]\",\"\", ow_clean).lower()\n",
        "            if ow_clean == w:\n",
        "                used.add(j)\n",
        "                orig_word = ow\n",
        "                punct_type = get_punctuation_type(sentence, s, e)\n",
        "                break\n",
        "        accent = 1 if tiene_acento(orig_word) else 0\n",
        "        pos_norm = round(i/(N-1), 2) if N>1 else 0.0\n",
        "        cap_type = get_capitalization_type(orig_word)\n",
        "        output.append({\n",
        "            'token': token_id,\n",
        "            'prev_token': prev_id,\n",
        "            'next_token': next_id,\n",
        "            'has_accent': accent,\n",
        "            'position': pos_norm,\n",
        "            'punctuation_type': punct_type,\n",
        "            'capitalization_type': cap_type\n",
        "        })\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5J60qHA7yOEu"
      },
      "outputs": [],
      "source": [
        "# ## 4. Build Vocabulary from Corpus\n",
        "# Load CSV corpus\n",
        "df = pd.read_csv('./full_corpus.csv')\n",
        "# Clean text\n",
        "sentences = df['text'].apply(limpiar_texto).tolist()\n",
        "# Build blob\n",
        "blob = \" \".join(sentences)\n",
        "blob = unicodedata.normalize(\"NFD\", blob).encode(\"ascii\",\"ignore\").decode(\"utf-8\")\n",
        "blob = re.sub(r\"[^a-zA-Z]+\",\" \", blob).lower().strip()\n",
        "# Token-to-index map\n",
        "def build_tokenizer(blob):\n",
        "    vocab, idx = {}, 0\n",
        "    for w in blob.split():\n",
        "        if w not in vocab:\n",
        "            vocab[w] = idx; idx += 1\n",
        "    return vocab\n",
        "word_to_index = build_tokenizer(blob)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J6v9oQpxyPtC"
      },
      "outputs": [],
      "source": [
        "# ## 5. Extract Features for All Tokens\n",
        "all_features = []\n",
        "for sent in sentences:\n",
        "    all_features.extend(procesar_oracion(sent, word_to_index))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MiC7Z6IGyRO-"
      },
      "outputs": [],
      "source": [
        "# ## 6. Prepare X and y for Three Tasks\n",
        "# Features for model\n",
        "X = [[f['token'], f['has_accent'], f['position']] for f in all_features]\n",
        "# Labels\n",
        "y_init = [1 if f['punctuation_type']==1 else 0 for f in all_features]  # apertura\n",
        "y_final = [1 if f['punctuation_type']==2 else 0 for f in all_features] # cierre\n",
        "# Multi-class for final punctuation: 0=ambas,1=apertura,2=cierre,3=punto,4=coma,5=ninguna\n",
        "y_punc_multi = [f['punctuation_type'] for f in all_features]\n",
        "# Capitalization classes\n",
        "y_cap = [f['capitalization_type'] for f in all_features]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BL9UnkXNyTCB"
      },
      "outputs": [],
      "source": [
        "# ## 7. Train/Test Split for Each Task\n",
        "X_train_i, X_test_i, y_train_i, y_test_i = train_test_split(X, y_init, test_size=0.2, random_state=42)\n",
        "X_train_f, X_test_f, y_train_f, y_test_f = train_test_split(X, y_final, test_size=0.2, random_state=42)\n",
        "X_train_m, X_test_m, y_train_m, y_test_m = train_test_split(X, y_punc_multi, test_size=0.2, random_state=42)\n",
        "X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(X, y_cap, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kh001NXSyUYd"
      },
      "outputs": [],
      "source": [
        "# %%\n",
        "# ## 8. Train Random Forests\n",
        "clf_init  = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "clf_final = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "clf_multi = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "clf_cap   = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "clf_init.fit(X_train_i, y_train_i)\n",
        "clf_final.fit(X_train_f, y_train_f)\n",
        "clf_multi.fit(X_train_m, y_train_m)\n",
        "clf_cap.fit(X_train_c, y_train_c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c-8gvURkyVmL"
      },
      "outputs": [],
      "source": [
        "# ## 9. Evaluation with F1-macro and Confusion Matrices\n",
        "for name, clf, X_t, y_t in [\n",
        "    ('Apertura', clf_init, X_test_i, y_test_i),\n",
        "    ('Cierre',  clf_final, X_test_f, y_test_f),\n",
        "    ('Multi-Punc',clf_multi, X_test_m, y_test_m),\n",
        "    ('Capitalización',clf_cap, X_test_c, y_test_c)\n",
        "]:\n",
        "    y_pred = clf.predict(X_t)\n",
        "    f1 = f1_score(y_t, y_pred, average='macro')\n",
        "    print(f\"F1-macro {name}: {f1:.4f}\")\n",
        "    cm = confusion_matrix(y_t, y_pred)\n",
        "    print(f\"Confusion matrix {name}:\\n\", cm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XF0szCeoyxS_"
      },
      "source": [
        "Esto reúne las predicciones de árbol:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K9cRvd3zyXgJ"
      },
      "outputs": [],
      "source": [
        "# ### Pipeline function (optional)\n",
        "def pipeline_full(sentence):\n",
        "    feats = procesar_oracion(sentence, word_to_index)\n",
        "    X_in = [[f['token'], f['has_accent'], f['position']] for f in feats]\n",
        "    pi = clf_init.predict(X_in); pf = clf_final.predict(X_in)\n",
        "    pm = clf_multi.predict(X_in); pc = clf_cap.predict(X_in)\n",
        "    out = []\n",
        "    for f, i_lbl, f_lbl, c_lbl in zip(feats, pi, pm, pc):\n",
        "        w = f.get('word', '')\n",
        "        # apply capitalization\n",
        "        if c_lbl==1: w = w.capitalize()\n",
        "        elif c_lbl==2 and len(w)>1: w = w[0].upper()+w[1:-1].lower()+w[-1].upper()\n",
        "        elif c_lbl==3: w = w.upper()\n",
        "        else: w = w.lower()\n",
        "        # apply punctuation (multi-label)\n",
        "        if f_lbl==1: w = '¿'+w\n",
        "        if i_lbl==1: w = w+'?'\n",
        "        out.append(w)\n",
        "    return ' '.join(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s4Prquwny10k"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python (venv)",
      "language": "python",
      "name": "aa"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "104c6b4f7d20409fb317f80164c55ca9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba7cebeb19fb4ce5b4cda46ea1a9affa",
            "max": 625,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1798cf914df24eee8c7b46162df09986",
            "value": 625
          }
        },
        "1798cf914df24eee8c7b46162df09986": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "199abaf82a3e463d9bd54e8975180dde": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19b25e120213459ebe67a274adf3c58a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1ae152f928cb4fb688509cc658c96e6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5afdcb13a3304ac28e427d2a69488e65",
            "max": 1961828,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_41222ae5b20f45d5aff34528c560e266",
            "value": 1961828
          }
        },
        "354833633d0540cd97308cfd10005fca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf854e94d0df4e3891bf6a157e2c2d14",
            "placeholder": "​",
            "style": "IPY_MODEL_6d6f156f63ee4b7cb6de655a242fa4e3",
            "value": " 996k/996k [00:00&lt;00:00, 7.93MB/s]"
          }
        },
        "3dc6a251ef35411c9bd817240b8f4956": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ecc83cfc76d4c2d928a7d16c04800a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e922d9dc57754231868ffadc76375006",
            "placeholder": "​",
            "style": "IPY_MODEL_a153731fb7bb4a23b80ec72b9e85c06f",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "3fda73286f7d416b8a7a763bda37022e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e1b6f9aea960412e8814906e6c99be31",
              "IPY_MODEL_104c6b4f7d20409fb317f80164c55ca9",
              "IPY_MODEL_5a12c1246c044d9d991561d2a6c0e781"
            ],
            "layout": "IPY_MODEL_72ae54ec9b904902a75b57c826fbb638"
          }
        },
        "41222ae5b20f45d5aff34528c560e266": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5a12c1246c044d9d991561d2a6c0e781": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_838b6d353d3a44e8bd157ee52cc4429d",
            "placeholder": "​",
            "style": "IPY_MODEL_ac8a3eceedff426591b379e62ed036e4",
            "value": " 625/625 [00:00&lt;00:00, 72.0kB/s]"
          }
        },
        "5afdcb13a3304ac28e427d2a69488e65": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c61856222c84ecbb7b4e8a78b10f027": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bbf72af5a20f4859ac9793f946000557",
            "placeholder": "​",
            "style": "IPY_MODEL_88e025156d5b4822ad1d3092aed1216c",
            "value": "tokenizer.json: 100%"
          }
        },
        "6858930ef8c243929648513bc3e6641b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d6f156f63ee4b7cb6de655a242fa4e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "72ae54ec9b904902a75b57c826fbb638": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "738eed1bbf064ae3be271ecc5d868e5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7721760a169543a7ac911ab04fd537f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89e6d6e0db724ad3aaef7ee983f4e1d6",
            "max": 49,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f2e040b12d104f1aafe8bdbe655351bd",
            "value": 49
          }
        },
        "7892671b63ca44d89eb190c9bf2640bb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b9f02008b794c2dbc344e5de8959f0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5c61856222c84ecbb7b4e8a78b10f027",
              "IPY_MODEL_1ae152f928cb4fb688509cc658c96e6b",
              "IPY_MODEL_7ec7f416d40445f6bc0790f7bedc89fd"
            ],
            "layout": "IPY_MODEL_ea71141b38794b1aa04eb8face044437"
          }
        },
        "7ec7f416d40445f6bc0790f7bedc89fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0d726b7592d459cac62a8926aeebaf3",
            "placeholder": "​",
            "style": "IPY_MODEL_92f8d075c23841879ab2d0dc4dd9b5b8",
            "value": " 1.96M/1.96M [00:00&lt;00:00, 26.0MB/s]"
          }
        },
        "838b6d353d3a44e8bd157ee52cc4429d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88e025156d5b4822ad1d3092aed1216c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "89e6d6e0db724ad3aaef7ee983f4e1d6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92f8d075c23841879ab2d0dc4dd9b5b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "963c1710dcb1458c8ee7255b7f2f712d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a153731fb7bb4a23b80ec72b9e85c06f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ac06e53bc71641de836852d7f095334a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ac64197189f04950a199c39822c1f346": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3ecc83cfc76d4c2d928a7d16c04800a0",
              "IPY_MODEL_7721760a169543a7ac911ab04fd537f8",
              "IPY_MODEL_e618e16b93c740d5b63c491748e435d4"
            ],
            "layout": "IPY_MODEL_199abaf82a3e463d9bd54e8975180dde"
          }
        },
        "ac8a3eceedff426591b379e62ed036e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b3728ffc5c644ba6b9eca05413ad3652": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7892671b63ca44d89eb190c9bf2640bb",
            "max": 995526,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_19b25e120213459ebe67a274adf3c58a",
            "value": 995526
          }
        },
        "ba7cebeb19fb4ce5b4cda46ea1a9affa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bbf72af5a20f4859ac9793f946000557": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bcb85f6493a041ea8ac6e517f248c89f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dd4e674b2f68476ba3fd6fd1870c9ddf",
              "IPY_MODEL_b3728ffc5c644ba6b9eca05413ad3652",
              "IPY_MODEL_354833633d0540cd97308cfd10005fca"
            ],
            "layout": "IPY_MODEL_bfe036ce67574d0faf56ab3069feb815"
          }
        },
        "bf854e94d0df4e3891bf6a157e2c2d14": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfe036ce67574d0faf56ab3069feb815": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0d726b7592d459cac62a8926aeebaf3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd4e674b2f68476ba3fd6fd1870c9ddf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea3b618300a44bc29737cbc7ce1f044a",
            "placeholder": "​",
            "style": "IPY_MODEL_963c1710dcb1458c8ee7255b7f2f712d",
            "value": "vocab.txt: 100%"
          }
        },
        "e1b6f9aea960412e8814906e6c99be31": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6858930ef8c243929648513bc3e6641b",
            "placeholder": "​",
            "style": "IPY_MODEL_738eed1bbf064ae3be271ecc5d868e5f",
            "value": "config.json: 100%"
          }
        },
        "e618e16b93c740d5b63c491748e435d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3dc6a251ef35411c9bd817240b8f4956",
            "placeholder": "​",
            "style": "IPY_MODEL_ac06e53bc71641de836852d7f095334a",
            "value": " 49.0/49.0 [00:00&lt;00:00, 3.50kB/s]"
          }
        },
        "e922d9dc57754231868ffadc76375006": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea3b618300a44bc29737cbc7ce1f044a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea71141b38794b1aa04eb8face044437": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2e040b12d104f1aafe8bdbe655351bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
